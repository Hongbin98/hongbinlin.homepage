<!DOCTYPE HTML>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <meta name="author" content="Hongbin Lin">
  <meta name="description" content="Hongbin Lin's Homepage">
  <meta name="keywords" content="Hongbin Lin,林宏彬,homepage,主页,3d object detection,autonomous driving,domain adaptation,Chinese University of Hong Kong, Shenzhen(CUHKSZ),South China University of Technology(SCUT)">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="8zswtwBqe_Jp-9UI2tXGtpDjMls3ztVqpwYmq64tKoQ" />
  <title>Hongbin Lin (林宏彬)'s Homepage</title>

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Hongbin Lin (林宏彬)</name>
              </p>
              <p style="text-align:center">
                Email: hongbinlin[at]link.cuhk.edu.cn &nbsp; &nbsp;&nbsp;&nbsp; <a href="https://scholar.google.com/citations?user=LqX1k5QAAAAJ&hl=en&oi=ao">Google Scholar </a>&nbsp; &nbsp;&nbsp;&nbsp;<a href="https://github.com/Hongbin98">Github</a>
              </p>
              <p>I am currently a PhD student at <a href="https://www.cuhk.edu.cn/en">the Chinese University of Hong Kong, Shenzhen</a> under the supervision of <a href="https://mypage.cuhk.edu.cn/academics/lizhen/">Prof. Zhen Li</a> and <a href="https://sse.cuhk.edu.cn/en/faculty/cuishuguang">Prof. Shuguang Cui</a> from 2024. In past years, I work closely with <a href="https://sites.google.com/view/yifan-zhang">Yifan Zhang</a> and <a href="https://niushuaicheng.cn/">Shuaicheng Niu</a>. My research interests are broadly in Autonomous Driving and mainly focus on: i) robustness-aware perception, ii) test-time out-of-distribution generalization and iii) robust end-to-end autonomous driving.
              </p>
              <p>Before that, I obtained both my Bachelor's (2016-2020) and Master's (2020-2023) degrees from South China University of Technology.</p>
            </td>
            <td style="padding:15% 7% 7% 7%;width:40%;max-width:40%">
              <a href="images/me_3.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/me_3.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr></tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" >
                  <video playsinline autoplay loop preload muted style="width:100%;max-width:100%; position: absolute;top: -5%">
                      <source src='images/thpad.mp4'>
                  </video>
              </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>DriveGEN: Generalized and Robust 3D Detection in Driving via Controllable Text-to-Image Diffusion Generation</papertitle>
              <br>
              Hongbin Lin</strong>, Zilu Guo, Yifan Zhang, Shuaicheng Niu, Yafeng Li, Ruimao Zhang, Shuguang Cui, Zhen Li
              <br>
              <em>CVPR</em> 2025,
              <br>
              <a href="https://www.arxiv.org/abs/2503.11122">[PDF]</a>
              <a href="https://github.com/Hongbin98/DriveGEN">[Code]</a>
              <a href="images/thpad.txt">[BibTeX]</a>
              <br>
              <div style="padding-left:2em;">
		<p>• Once the environment changes, well-trained detectors may suffer performance degradation due to the existence of data distribution shifts between training images and test images.</p>
		<p>• We propose DriveGEN, a training-free controllable generative method to transform existing training images into various corrupted scenarios.</p>
		<p>• By preserving 3D objects, it boosts model robustness via generative model without any parameter modification.</p>
              </div>
          </td>
      </tr>

        <tr></tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one" >
                    <video playsinline autoplay loop preload muted style="width:100%;max-width:100%; position: absolute;top: -5%">
                        <source src='images/pdfgc.mp4'>
                    </video>
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Progressive Disentangled Representation Learning for Fine-Grained Controllable Talking Head Synthesis</papertitle>
                <br>
                Duomin Wang, Yu Deng, <strong>Hongbin Lin</strong>, Heung-Yeung Shum, Baoyuan Wang
                <br>
                <em>CVPR</em> 2023,
                <br>
                <a href="https://arxiv.org/abs/2211.14506">[PDF]</a>
                <a href="https://dorniwang.github.io/PD-FGC/">[Project]</a>
                <a href="">[Code(coming soon)]</a>
				<a href="images/pdfgc.txt">[BibTeX]</a>
                <br>
                <p>We present a novel one-shot talking head synthesis method that achieves disentangled and fine-grained control over lip motion, eye gaze&blink, head pose, and emotional expression.
                     We represent different motions via disentangled latent representations and leverage an image generator to synthesize talking heads from them.</p>
            </td>
        </tr>

        <tr></tr>
        <td>
          <em>(* means equal contribution)</em>
        </td>
        </tr>

        <tr></tr>
            <td style="padding:20px;width:0%;vertical-align:middle">
            </td>
            <td style="padding:20px;width:100%;vertical-align:middle">
		<hr style="margin-top:0px">
                <p>The website template was adapted from <a href="https://zxyin.github.io/">Zixin Yin</a>.</p>
            </td>
        </tr>

      </td>
    </tr>
  </table>
</body>

</html>
